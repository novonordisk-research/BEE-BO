

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>beebo.acquisition &mdash; BEEBO 0.0.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=e3a6060d"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            BEEBO
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beebo.html">beebo package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">beebo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">BEEBO</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">beebo.acquisition</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for beebo.acquisition</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.analytic</span><span class="w"> </span><span class="kn">import</span> <span class="n">AnalyticAcquisitionFunction</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">BotorchWarning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">t_batch_mode_transform</span><span class="p">,</span> <span class="n">concatenate_pending_points</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultivariateNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.utils.cholesky</span><span class="w"> </span><span class="kn">import</span> <span class="n">psd_safe_cholesky</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.cholesky_inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPPosteriorPredictor</span>


<div class="viewcode-block" id="LogDetMethod">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.LogDetMethod">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogDetMethod</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used to specify the method for computing the log determinant of the covariance matrices in the :class:`~BatchedEnergyEntropyBO` acquisition function.</span>
<span class="sd">    </span>
<span class="sd">    SVD</span>
<span class="sd">        Computes the log determinant using singular value decomposition.</span>
<span class="sd">    CHOLESKY</span>
<span class="sd">        Computes the log determinant using the cholesky decomposition, taking advantage of the fact that the covariance matrix is positive definite. This </span>
<span class="sd">        is not always numerically stable.</span>
<span class="sd">    TORCH</span>
<span class="sd">        Computes the log determinant using the default torch function `torch.logdet`. This is not always numerically stable.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">SVD</span> <span class="o">=</span> <span class="s2">&quot;svd&quot;</span>
    <span class="n">CHOLESKY</span> <span class="o">=</span> <span class="s2">&quot;cholesky&quot;</span>
    <span class="n">TORCH</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span></div>


<div class="viewcode-block" id="AugmentedPosteriorMethod">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.AugmentedPosteriorMethod">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AugmentedPosteriorMethod</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Used to specify the method for augmenting the GP model with new points </span>
<span class="sd">    and computing the posterior covariance after augmentation in the :class:`~BatchedEnergyEntropyBO` acquisition function.</span>

<span class="sd">    NAIVE</span>
<span class="sd">        We keep a copy of the original model and augment it with the new points using the</span>
<span class="sd">        ``set_train_data`` method each time we evaluate the acquisition function. This is memory safe but slow.</span>
<span class="sd">    CHOLESKY</span>
<span class="sd">        We perform a low rank update to the cholesky decomposition of the training covariance, adding the new points.</span>
<span class="sd">        This is fast, but circumvents the default GPyTorch inference in favor of cholesky-based predictions. Uses</span>
<span class="sd">        :class:`~beebo.utils.cholesky_inference.GPPosteriorPredictor` to compute the augmented covariance.</span>
<span class="sd">    GET_FANTASY_MODEL</span>
<span class="sd">        We use the ``get_fantasy_model`` method of the GP model to get a new model with the new points. This is not memory safe</span>
<span class="sd">        when running with gradients enabled.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">NAIVE</span> <span class="o">=</span> <span class="s2">&quot;naive&quot;</span>
    <span class="n">CHOLESKY</span> <span class="o">=</span> <span class="s2">&quot;cholesky&quot;</span>
    <span class="n">GET_FANTASY_MODEL</span> <span class="o">=</span> <span class="s2">&quot;get_fantasy_model&quot;</span> <span class="c1"># NOTE this isn&#39;t memory safe yet</span></div>

    <span class="c1"># TODO replace with a wrapper for GET_FANTASY_STRATEGY --&gt; skip the internal model deepcopy</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.operators</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">DiagLinearOperator</span><span class="p">,</span>
                                       <span class="n">LowRankRootLinearOperator</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.utils.cholesky</span><span class="w"> </span><span class="kn">import</span> <span class="n">psd_safe_cholesky</span>


<div class="viewcode-block" id="stable_softmax">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.stable_softmax">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">stable_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">f_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    
    <span class="k">if</span> <span class="n">f_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_scaled</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x_scaled</span> <span class="o">-</span> <span class="n">x_scaled</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="c1"># (n x q+1)</span>
        <span class="n">z_exp</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">z_exp</span> <span class="o">/</span> <span class="n">z_exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># (n x q)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_scaled</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x</span>
        <span class="n">beta_delta_x</span> <span class="o">=</span> <span class="n">x_scaled</span> <span class="o">-</span> <span class="n">x_scaled</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">beta_delta_fmax</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">f_max</span> <span class="o">-</span> <span class="n">x_scaled</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">beta_delta_x</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">denominator</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_delta_fmax</span><span class="o">.</span><span class="n">exp</span><span class="p">()],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">beta_delta_x</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">denominator</span><span class="o">+</span><span class="n">g</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">w</span></div>


<div class="viewcode-block" id="softmax_expectation_a_is_mean">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.softmax_expectation_a_is_mean">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">softmax_expectation_a_is_mean</span><span class="p">(</span><span class="n">mvn</span><span class="p">,</span> <span class="n">softmax_beta</span><span class="p">,</span> <span class="n">f_max</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="n">means</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">mean</span> <span class="c1"># (n x q)</span>
    <span class="n">covar</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">covariance_matrix</span> <span class="c1"># (n x q x q)</span>
    <span class="n">lazy_covar</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span> <span class="c1"># (n x q x q)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">stable_softmax</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">softmax_beta</span><span class="p">,</span> <span class="n">f_max</span><span class="p">)</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">-</span> <span class="n">LowRankRootLinearOperator</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># (n x q x q)</span>

    <span class="n">U_inv</span> <span class="o">=</span> <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">covar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">means</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> <span class="o">+</span> <span class="n">softmax_beta</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">lazy_covar</span> <span class="o">@</span> <span class="n">W</span>

    <span class="c1"># avoid doing a solve for C_update.</span>
    <span class="n">col_difference</span> <span class="o">=</span> <span class="n">U_inv</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">covar</span> <span class="o">-</span> <span class="n">covar</span> <span class="o">@</span> <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># this is C_update - C_update @ w.unsqueeze(-1)</span>
    <span class="n">nu_i_matrix</span> <span class="o">=</span> <span class="n">softmax_beta</span> <span class="o">*</span>  <span class="n">col_difference</span> <span class="o">+</span> <span class="n">means</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (n x q x q)</span>
    

    <span class="n">c_i_vector</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">softmax_beta</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">col_difference</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="o">-</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mT</span> <span class="o">@</span> <span class="n">col_difference</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># (n x 1 x q)</span>
    <span class="p">)</span> <span class="c1"># n x q</span>

    <span class="n">K</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">U_inv</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span><span class="o">.</span><span class="n">det</span><span class="p">())</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">expectation</span> <span class="o">=</span> <span class="n">K</span> <span class="o">*</span> <span class="p">((</span><span class="n">w</span><span class="o">.</span><span class="n">log</span><span class="p">()</span> <span class="o">+</span> <span class="n">c_i_vector</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">nu_i_matrix</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expectation</span></div>



<div class="viewcode-block" id="softmax_expectation">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.softmax_expectation">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">softmax_expectation</span><span class="p">(</span><span class="n">mvn</span><span class="p">:</span> <span class="n">MultivariateNormal</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">softmax_beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">f_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

    <span class="c1"># NOTE we are using the simplified expressions that arise when the expansion point is the mean of the MVN.</span>
    <span class="n">shortcut_expectation</span> <span class="o">=</span> <span class="n">softmax_expectation_a_is_mean</span><span class="p">(</span><span class="n">mvn</span><span class="p">,</span> <span class="n">softmax_beta</span><span class="p">,</span> <span class="n">f_max</span><span class="p">)</span>
    <span class="n">expectation</span> <span class="o">=</span> <span class="n">shortcut_expectation</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">expectation</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">ipdb</span><span class="p">;</span> <span class="n">ipdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;nan in expectation&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">expectation</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;inf in expectation&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">expectation</span></div>




<div class="viewcode-block" id="EnergyFunction">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.EnergyFunction">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">EnergyFunction</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used to specify the energy function to be used in the :class:`~BatchedEnergyEntropyBO` acquisition function.</span>
<span class="sd">    </span>
<span class="sd">    SOFTMAX</span>
<span class="sd">        Implements maxBEEBO. This option will lead the acquisition function to focus more on the point with the highest expected improvement in the batch.</span>
<span class="sd">        If this is chosen, :class:`~BatchedEnergyEntropyBO` accepts the additional arguments ``softmax_beta`` and ``f_max``. </span>
<span class="sd">        ``softmax_beta`` is a scalar representing the inverse temperature of the softmax function.</span>
<span class="sd">        ``f_max`` is a scalar representing the maximum value of the function to be optimized.</span>
<span class="sd">    SUM</span>
<span class="sd">        Implements meanBEEBO. This option will lead the acquisition function to focus on improving the overall batch.</span>

<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">SOFTMAX</span> <span class="o">=</span> <span class="s2">&quot;softmax&quot;</span>
    <span class="n">SUM</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span></div>



<div class="viewcode-block" id="BatchedEnergyEntropyBO">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.BatchedEnergyEntropyBO">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BatchedEnergyEntropyBO</span><span class="p">(</span><span class="n">AnalyticAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The BEEBO batch acquisition function. Jointly optimizes a batch of points by minimizing</span>
<span class="sd">    the free energy of the batch.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (GPyTorch Model): A fitted single-outcome GP model. Must be in batch mode if</span>
<span class="sd">            candidate sets X will be.</span>
<span class="sd">        temperature (float): A scalar representing the temperature. </span>
<span class="sd">            Higher temperature leads to more exploration.</span>
<span class="sd">        kernel_amplitude (float, optional): The amplitude of the kernel. Defaults to 1.0.</span>
<span class="sd">            This is used to bring the temperature to a scale that is comparable to </span>
<span class="sd">            UCB&#39;s hyperparameter `beta`.</span>
<span class="sd">        posterior_transform (PosteriorTransform, optional): A PosteriorTransform. If using a multi-output model,</span>
<span class="sd">            a PosteriorTransform that transforms the multi-output posterior into a</span>
<span class="sd">            single-output posterior is required.</span>
<span class="sd">        maximize (bool, optional): If True, consider the problem a maximization problem. Defaults to False.</span>
<span class="sd">        logdet_method (str, optional): The method to use to compute the log determinant of the</span>
<span class="sd">            covariance matrix. Should be one of the members of the :class:`~LogDetMethod` enum: </span>
<span class="sd">            ``&quot;svd&quot;``, ``&quot;cholesky&quot;``, or ``&quot;torch&quot;``. Defaults to ``&quot;svd&quot;``.</span>
<span class="sd">        augment_method (str, optional): The method to use to augment the model with the new points</span>
<span class="sd">            and computing the posterior covariance. Should be one of the members of the :class:`~AugmentedPosteriorMethod` enum:</span>
<span class="sd">            ``&quot;naive&quot;`` or ``&quot;cholesky&quot;``. Defaults to ``&quot;naive&quot;``.</span>
<span class="sd">        energy_function (str, optional): The energy function to use in the BEEBO acquisition function. </span>
<span class="sd">            Should be a string representing one of the members of the :class:`~EnergyFunction` enum: ``&quot;softmax&quot;`` or ``&quot;sum&quot;``. </span>
<span class="sd">            &quot;softmax&quot; implements the maxBEEBO and &quot;sum&quot; implements the meanBEEBO. Defaults to ``&quot;sum&quot;``.</span>
<span class="sd">        **kwargs: Additional arguments to be passed to the energy function.</span>



<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">kernel_amplitude</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">logdet_method</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">LogDetMethod</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;svd&quot;</span><span class="p">,</span>
        <span class="n">augment_method</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">AugmentedPosteriorMethod</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;naive&quot;</span><span class="p">,</span>
        <span class="n">energy_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">EnergyFunction</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logdet_method</span> <span class="o">=</span> <span class="n">LogDetMethod</span><span class="p">[</span><span class="n">logdet_method</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logdet_method</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">logdet_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">=</span> <span class="n">AugmentedPosteriorMethod</span><span class="p">[</span><span class="n">augment_method</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">augment_method</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">augment_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">energy_function</span> <span class="o">=</span> <span class="n">EnergyFunction</span><span class="p">[</span><span class="n">energy_function</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">energy_function</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">energy_function</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">energy_function</span> <span class="o">==</span> <span class="n">EnergyFunction</span><span class="o">.</span><span class="n">SOFTMAX</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">softmax_beta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;softmax_beta&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;f_max&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
 
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_amplitude</span> <span class="o">=</span> <span class="n">kernel_amplitude</span>
 
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_amplitude</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span> <span class="o">=</span> <span class="n">maximize</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_pending</span><span class="p">(</span><span class="n">X_pending</span><span class="p">)</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">==</span> <span class="n">AugmentedPosteriorMethod</span><span class="o">.</span><span class="n">CHOLESKY</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">GPPosteriorPredictor</span><span class="p">(</span>
                <span class="n">model</span><span class="o">.</span><span class="n">covar_module</span><span class="p">,</span>
                <span class="n">model</span><span class="o">.</span><span class="n">mean_module</span><span class="p">,</span>
                <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="p">,</span>
                <span class="n">train_X</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">train_y</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">train_targets</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">==</span> <span class="n">AugmentedPosteriorMethod</span><span class="o">.</span><span class="n">NAIVE</span><span class="p">:</span>
            <span class="c1"># for augmentation, we keep a copy of the original model</span>
            <span class="c1"># if we make a copy in the forward pass only, we get a memory leak</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># self.summary_fn = torch.sum</span>

        

<div class="viewcode-block" id="BatchedEnergyEntropyBO.forward">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.BatchedEnergyEntropyBO.forward">[docs]</a>
    <span class="nd">@concatenate_pending_points</span>    
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the free energy of the candidate set X.</span>
<span class="sd">        Args:</span>
<span class="sd">            X: A `(b1 x ... bk) x q x d`-dim batched tensor of `d`-dim design points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `(b1 x ... bk)`-dim tensor of BOSS values at the</span>
<span class="sd">            given design points `X`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># required for gradients in augmented GPs.</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">detach_test_caches</span><span class="p">(</span><span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            
            <span class="c1"># Entropy term.</span>
            <span class="n">f_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># this gets p(f* | x*, X, y) with x* being test points.</span>
            <span class="n">posterior_cov</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">covariance_matrix</span> <span class="c1">#  == C&#39;_D</span>
            <span class="n">posterior_means</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">mean</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">==</span> <span class="n">AugmentedPosteriorMethod</span><span class="o">.</span><span class="n">NAIVE</span><span class="p">:</span>
                <span class="c1"># augment the training data with the test points</span>
                <span class="n">X_train_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">Y_train_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_targets</span>
                <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_original</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_train_original</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_train_original</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># (n_batch, n_train, dim)</span>
                <span class="n">Y_train</span> <span class="o">=</span> <span class="n">Y_train_original</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y_train_original</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># (n_batch, n_train)</span>
                <span class="n">X_train_augmented</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (n_batch, n_train + n_aug, dim)</span>
                <span class="n">Y_train_augmented</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">])],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (n_batch, n_train + n_aug)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">augmented_model</span><span class="o">.</span><span class="n">set_train_data</span><span class="p">(</span><span class="n">X_train_augmented</span><span class="p">,</span> <span class="n">Y_train_augmented</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">f_preds_augmented</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="n">posterior_means_augmented</span> <span class="o">=</span> <span class="n">f_preds_augmented</span><span class="o">.</span><span class="n">mean</span>
                <span class="n">posterior_cov_augmented</span> <span class="o">=</span> <span class="n">f_preds_augmented</span><span class="o">.</span><span class="n">covariance_matrix</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">==</span> <span class="n">AugmentedPosteriorMethod</span><span class="o">.</span><span class="n">CHOLESKY</span><span class="p">:</span>
                <span class="n">posterior_cov_augmented</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="o">.</span><span class="n">augmented_covariance</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="n">posterior_means_augmented</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_means</span><span class="p">)</span> <span class="c1">#not used</span>


            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">==</span> <span class="n">AugmentedPosteriorMethod</span><span class="o">.</span><span class="n">GET_FANTASY_MODEL</span><span class="p">:</span>
                <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_fantasy_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]))</span>
                <span class="n">f_preds_augmented</span> <span class="o">=</span> <span class="n">fantasy_model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="n">posterior_means_augmented</span> <span class="o">=</span> <span class="n">f_preds_augmented</span><span class="o">.</span><span class="n">mean</span>
                <span class="n">posterior_cov_augmented</span> <span class="o">=</span> <span class="n">f_preds_augmented</span><span class="o">.</span><span class="n">covariance_matrix</span>




            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logdet_method</span> <span class="o">==</span> <span class="n">LogDetMethod</span><span class="o">.</span><span class="n">CHOLESKY</span><span class="p">:</span>
                <span class="c1"># use cholesky decomposition to compute logdet, fallback to svd if fails</span>
                <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">cholesky_max_tries</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">posterior_cov_logdet</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span><span class="o">.</span><span class="n">logdet</span><span class="p">()</span>
                        <span class="c1"># also trigger exception when any nan in result</span>
                        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">posterior_cov_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;nan in logdet&#39;</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">posterior_cov_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;inf in logdet&#39;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cholesky failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                        <span class="n">_</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">posterior_cov</span><span class="p">)</span>
                        <span class="n">posterior_cov_logdet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">augment_method</span> <span class="o">==</span> <span class="n">AugmentedPosteriorMethod</span><span class="o">.</span><span class="n">CHOLESKY</span><span class="p">:</span>
                            <span class="c1"># there is no lazy_covariance_matrix if we use cholesky augmentation</span>
                            <span class="n">chol</span> <span class="o">=</span> <span class="n">psd_safe_cholesky</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="p">)</span>
                            <span class="n">posterior_cov_augmented_logdet</span> <span class="o">=</span> <span class="n">chol</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
                            <span class="c1"># posterior_cov_augmented_logdet = torch.logdet(posterior_cov_augmented)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">posterior_cov_augmented_logdet</span> <span class="o">=</span> <span class="n">f_preds_augmented</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span><span class="o">.</span><span class="n">logdet</span><span class="p">()</span>
                        <span class="c1"># also trigger exception when any nan in result</span>
                        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">posterior_cov_augmented_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;nan in logdet&#39;</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">posterior_cov_augmented_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;inf in logdet&#39;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cholesky failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                        <span class="n">_</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="p">)</span>
                        <span class="n">posterior_cov_augmented_logdet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">logdet_method</span> <span class="o">==</span> <span class="n">LogDetMethod</span><span class="o">.</span><span class="n">SVD</span><span class="p">:</span>
                <span class="c1"># use svd to compute logdet</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="p">)</span>
                <span class="c1"># s[s==0] = 1e-20 # avoid nan # same but autograd friendly</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">s</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-20</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
                <span class="n">posterior_cov_augmented_logdet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">(</span><span class="n">posterior_cov</span><span class="p">)</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">s</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-20</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="c1"># avoid nan</span>
                <span class="n">posterior_cov_logdet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">logdet_method</span> <span class="o">==</span> <span class="n">LogDetMethod</span><span class="o">.</span><span class="n">TORCH</span><span class="p">:</span>
                <span class="n">posterior_cov</span> <span class="o">=</span> <span class="n">posterior_cov</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">posterior_cov</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">posterior_cov</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-06</span>
                <span class="n">posterior_cov_logdet</span> <span class="o">=</span>  <span class="n">torch</span><span class="o">.</span><span class="n">logdet</span><span class="p">(</span><span class="n">posterior_cov</span><span class="p">)</span>    
                <span class="n">posterior_cov_augmented</span> <span class="o">=</span> <span class="n">posterior_cov_augmented</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">posterior_cov_augmented</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-0</span>
                <span class="n">posterior_cov_augmented_logdet</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logdet</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;logdet method </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logdet_method</span><span class="si">}</span><span class="s1"> not implemented&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">posterior_cov_augmented_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;augmented cov logdet is inf&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">posterior_cov_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cov logdet is inf&#39;</span><span class="p">)</span>


            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">posterior_cov_augmented_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;augmented cov logdet is nan&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">posterior_cov_logdet</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cov logdet is nan&#39;</span><span class="p">)</span>

            <span class="n">information_gain</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span> <span class="p">(</span><span class="n">posterior_cov_logdet</span> <span class="o">-</span> <span class="n">posterior_cov_augmented_logdet</span><span class="p">)</span>

            

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">energy_function</span> <span class="o">==</span> <span class="n">EnergyFunction</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span>
                <span class="n">summary_posterior</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior_means</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">summary_augmented</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior_means_augmented</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">energy_function</span> <span class="o">==</span> <span class="n">EnergyFunction</span><span class="o">.</span><span class="n">SOFTMAX</span><span class="p">:</span>
                <span class="n">summary_posterior</span> <span class="o">=</span> <span class="n">softmax_expectation</span><span class="p">(</span><span class="n">f_preds</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">f_preds</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">softmax_beta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">softmax_beta</span><span class="p">,</span> <span class="n">f_max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">f_max</span><span class="p">)</span>
                <span class="n">summary_posterior</span> <span class="o">=</span> <span class="n">summary_posterior</span> <span class="o">*</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># multiply by q to make it scale linearly with q, like logdet</span>

                <span class="c1"># this is a dummy thing for memory leaks</span>
                <span class="n">summary_augmented</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior_means_augmented</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span><span class="p">:</span>
                <span class="c1"># maximize fn value + gain</span>
                <span class="n">acq_value</span> <span class="o">=</span>  <span class="n">summary_posterior</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">*</span> <span class="n">information_gain</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">acq_value</span> <span class="o">=</span>  <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">summary_posterior</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">*</span> <span class="n">information_gain</span>

            <span class="n">acq_value</span> <span class="o">+=</span> <span class="n">summary_augmented</span><span class="o">*</span><span class="mi">0</span> <span class="c1"># this prevents memory leaks.</span>

            <span class="c1"># print(&#39;acq&#39;, &#39;info gain&#39;, &#39;expect.&#39;, &#39;sum&#39;,&#39;max&#39;)</span>
            <span class="c1"># print_array = torch.stack([acq_value, information_gain, summary_posterior, posterior_means.sum(1), posterior_means.max(1).values], dim=1) # (num_restarts, 5)</span>
            <span class="c1"># print_array = np.array_str(print_array.detach().cpu().numpy().mean(axis=0), precision=3, suppress_small=True)</span>
            <span class="c1"># print(print_array)</span>


            <span class="k">return</span> <span class="n">acq_value</span></div>


    <span class="c1"># NOTE the base AnalyticAcquisitionFunction class does not support X_pending</span>
<div class="viewcode-block" id="BatchedEnergyEntropyBO.set_X_pending">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.BatchedEnergyEntropyBO.set_X_pending">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_X_pending</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Informs the acquisition function about pending design points.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_pending: `n x d` Tensor with `n` `d`-dim design points that have</span>
<span class="sd">                been submitted for evaluation but have not yet been evaluated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X_pending</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># when doing sequential, stuff will have gradients. no point in</span>
            <span class="c1"># warning about it.</span>
            <span class="c1"># if X_pending.requires_grad:</span>
            <span class="c1">#     warnings.warn(</span>
            <span class="c1">#         &quot;Pending points require a gradient but the acquisition function&quot;</span>
            <span class="c1">#         &quot; will not provide a gradient to these points.&quot;,</span>
            <span class="c1">#         BotorchWarning,</span>
            <span class="c1">#     )</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="o">=</span> <span class="n">X_pending</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="o">=</span> <span class="n">X_pending</span></div>



    <span class="c1"># NOTE the methods below are only there for better readability.</span>
    <span class="c1"># Due to memory leaks and for numerical reasons, they are not used in the actual code.</span>
    <span class="c1"># We keep them here for future reference, as a minimal example of how to compute the</span>
    <span class="c1"># two terms of the BEE-BOSS acquisition function.</span>
<div class="viewcode-block" id="BatchedEnergyEntropyBO.compute_energy">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.BatchedEnergyEntropyBO.compute_energy">[docs]</a>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_energy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the energy of the candidate set X. </span>
<span class="sd">        Args:</span>
<span class="sd">            X: A `(b1 x ... bk) x q x d`-dim batched tensor of `d`-dim design points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `(b1 x ... bk)`-dim tensor of BOSS values at the</span>
<span class="sd">            given design points `X`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">detach_test_caches</span><span class="p">(</span><span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="c1"># Enthalpy term.</span>
            <span class="n">f_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># this gets p(f* | x*, X, y) with x* being test points.</span>
            <span class="n">posterior_means</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">mean</span>

            <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_fn</span><span class="p">(</span><span class="n">posterior_means</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 


            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span><span class="p">:</span>
                <span class="c1"># minimize fn value + maximize gain</span>
                <span class="n">summary</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">summary</span>
            
            <span class="k">return</span> <span class="n">summary</span></div>

        

<div class="viewcode-block" id="BatchedEnergyEntropyBO.compute_entropy">
<a class="viewcode-back" href="../../beebo.html#beebo.acquisition.BatchedEnergyEntropyBO.compute_entropy">[docs]</a>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the energy of the candidate set X. </span>
<span class="sd">        Args:</span>
<span class="sd">            X: A `(b1 x ... bk) x q x d`-dim batched tensor of `d`-dim design points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `(b1 x ... bk)`-dim tensor of information gain values at the</span>
<span class="sd">            given design points `X`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">detach_test_caches</span><span class="p">(</span><span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="c1"># Entropy term.</span>
            <span class="n">f_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># this gets p(f* | x*, X, y) with x* being test points.</span>
            <span class="n">posterior_cov</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">covariance_matrix</span> <span class="c1">#  == C&#39;_D</span>

            <span class="c1">## augment observations with x&#39; and dummy y&#39; (because gpytorch requires them)</span>
            <span class="n">model_augmented</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_fantasy_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]))</span> 
            <span class="n">f_preds</span> <span class="o">=</span> <span class="n">model_augmented</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">posterior_cov_augmented</span> <span class="o">=</span> <span class="n">f_preds</span><span class="o">.</span><span class="n">covariance_matrix</span> <span class="c1"># == C&#39;_D_D&#39;</span>
            <span class="n">posterior_cov_augmented</span> <span class="o">=</span> <span class="n">posterior_cov_augmented</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">posterior_cov_augmented</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-04</span>

            <span class="n">information_gain</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logdet</span><span class="p">(</span><span class="n">posterior_cov</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">logdet</span><span class="p">(</span><span class="n">posterior_cov_augmented</span><span class="p">)</span>


            <span class="k">return</span> <span class="n">information_gain</span></div>
</div>







</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, F Teufel, C Stahlhut, J Ferkinghoff-Borg.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>